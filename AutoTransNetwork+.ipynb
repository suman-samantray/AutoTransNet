{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MDAnalysis as md # distances in Angstroem\n",
    "from MDAnalysis.lib.pkdtree import PeriodicKDTree\n",
    "from MDAnalysis.lib.distances import distance_array\n",
    "from MDAnalysis.analysis.dihedrals import Ramachandran\n",
    "from sklearn.cluster import KMeans\n",
    "import mdtraj # necessary for dssp\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionNetworks:\n",
    "    topology = None\n",
    "    trajectory = None\n",
    "    nChains = 0\n",
    "    state = []\n",
    "    \n",
    "    \"\"\"The descriptors and corresponding cutoffs to use for constructing the transition matrix.\"\"\"\n",
    "    descriptors = {}\n",
    "    \n",
    "    def __init__(self, top=topology, traj=trajectory, nChains=nChains,\\\n",
    "                 desc=descriptors, state=state, binEdges=list(), nCapping=True,\\\n",
    "                 cCapping=True, h5File='transitionNetwork.hdf5'):\n",
    "        self.top = top\n",
    "        self.traj = traj\n",
    "        self.universe = md.Universe(top, traj)\n",
    "        self.nChains = nChains\n",
    "        self.nAtomsPerChain = int(self.universe.trajectory.n_atoms/self.nChains)\n",
    "        self.nResiduesPerChain = int(len(self.universe.residues)/self.nChains)\n",
    "        self.nFrames = self.universe.trajectory.n_frames\n",
    "        self.state = state\n",
    "        self.binEdges = binEdges\n",
    "        self.nCapping = nCapping\n",
    "        self.cCapping = cCapping\n",
    "        self.h5File = h5File\n",
    "        \n",
    "        \"\"\"Sort the descriptors dictionary by cutoffs in decreasing order.\"\"\"\n",
    "        self.descriptors = {k: v for k, v in sorted(desc.items(), key=lambda item: -item[1])}\n",
    "\n",
    "        \"\"\"Generate array with cutoff values in decreasing order.\"\"\"\n",
    "        self.cutoffs = np.unique(list(self.descriptors.values()))[::-1]\n",
    "        \n",
    "        \"\"\"Generate array to connect atom indices with residue names.\"\"\"\n",
    "        self.resnames = self.universe.atoms.resnames\n",
    "        \n",
    "        \"\"\"Generate array to connect atom indices with residue indices.\"\"\"\n",
    "        self.resindices = self.universe.atoms.resindices\n",
    "        \n",
    "        \"\"\"Generate a dictionary which enables to extract the atom index of a alpha carbon\n",
    "        or nitrogen atom when giving a residue's index as input.\"\"\"\n",
    "        nAtomsDict = {}\n",
    "        cAAtomsDict = {}\n",
    "        for atomIdx, atom in enumerate(self.universe.atoms[:self.nAtomsPerChain], 0):\n",
    "            if (atom.name == 'CA'):\n",
    "                for chainIdx in range(nChains):\n",
    "                    cAAtomsDict.update({atom.resnum + chainIdx*self.nResiduesPerChain: atomIdx + chainIdx*self.nAtomsPerChain})\n",
    "            elif (atom.name == 'N'):\n",
    "                for chainIdx in range(nChains):\n",
    "                    nAtomsDict.update({atom.resnum + chainIdx*self.nResiduesPerChain: atomIdx + chainIdx*self.nAtomsPerChain})\n",
    "        self.nAtomsDict = nAtomsDict\n",
    "        self.cAAtomsDict = cAAtomsDict\n",
    "    \n",
    "    \n",
    "    def _intermolecularContactPairs(self):\n",
    "        \"\"\"The largest cutoff value 'cutoff0' defines the search distance for the k-d tree.\"\"\"\n",
    "        cutoff0 = self.cutoffs[0]\n",
    "        \n",
    "        \"\"\"All other cutoffs are stored in the array cutoffs1\"\"\"\n",
    "        cutoffs1 = self.cutoffs[1:]\n",
    "\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            \"\"\"Create/Check if group 'contactPairs' is present in the file. Structure\n",
    "            of this group is: (nFrames, nCutoffs, contactPairs[cutoff]).\"\"\"\n",
    "            group = f.require_group(name='contactPairs')\n",
    "            \n",
    "            for frameIdx, frame in enumerate(self.universe.trajectory):\n",
    "                frameIdx = str(frameIdx)\n",
    "                \n",
    "                \"\"\"Extract the unit cell information 'box' and the concatenated positions\n",
    "                'pos Concatenated' for every frame.\"\"\"\n",
    "                box = frame.dimensions\n",
    "                posConcatenated = frame.positions\n",
    "                \n",
    "                \"\"\"Initialize the periodic k-d tree 'tree' with the unit cell information.\n",
    "                From MD analysis online documentation:\n",
    "                Number of entries in leafs of the KDTree. If you suffer poor performance \n",
    "                you can play around with this number. Increasing the leafsize will speed\n",
    "                up the construction of the KDTree but slow down the search.\"\"\"\n",
    "                tree = PeriodicKDTree(box=box, leafsize=5)\n",
    "                \n",
    "                \"\"\"Reshape the positions array from shape (nAtomsPerChain*nChains, 3) to\n",
    "                (nChains, nAtomsPerChain, 3) 'pos'.\"\"\"\n",
    "                pos = np.split(posConcatenated, self.nChains)\n",
    "\n",
    "                \"\"\"Build the k-d tree using the coordinates of one chain and then search\n",
    "                all intermolecular contacts using the coordinates of the remaining chains.\"\"\"\n",
    "                contactPairs = list([] for d in self.cutoffs)\n",
    "                for excludeChain in range(self.nChains-1):\n",
    "                    \n",
    "                    \"\"\"Extract the coordinates of one chain.\"\"\"\n",
    "                    excludePos = pos[excludeChain]\n",
    "\n",
    "                    \"\"\"Build the k-d tree using these coordinates. From MD analysis online\n",
    "                    documentation: 'cutoff': Specified cutoff distance to create duplicate images.\n",
    "                    Typically equivalent to the desired search radius or the maximum of the \n",
    "                    desired cutoff radius.\"\"\"\n",
    "                    tree.set_coords(excludePos, cutoff=cutoff0)\n",
    "\n",
    "                    \"\"\"Extract the coordinates of the remaining chains.\"\"\"\n",
    "                    includeChains = [chain for chain in range(excludeChain+1, self.nChains)]\n",
    "                    includePos = np.concatenate([pos[chain] for chain in includeChains])\n",
    "                    \n",
    "                    \"\"\"Extract all intermolecular contact pairs within the cutoff0 and correct atom\n",
    "                    indicies.\"\"\"\n",
    "                    for pair in tree.search_tree(includePos, cutoff0):                \n",
    "                        atomIdxChainA = pair[1] + excludeChain*self.nAtomsPerChain\n",
    "                        atomIdxChainB = pair[0] + (excludeChain+1)*self.nAtomsPerChain\n",
    "\n",
    "                        \"\"\"Compute the exact distance of this intermolecular distance pair using pbc.\"\"\"\n",
    "                        distance = distance_array(posConcatenated[atomIdxChainA],\n",
    "                                                  posConcatenated[atomIdxChainB],\n",
    "                                                  box=box)[0][0]\n",
    "\n",
    "                        \"\"\"Compare the calculated distance with the given cutoffs, stop if cutoff is\n",
    "                        greater than the given value. 'depth' allows to return the 'stop cutoff' value\n",
    "                        by self.cutoffs[depth].\"\"\"\n",
    "                        depth = 0\n",
    "                        for cValue in cutoffs1:\n",
    "                            if (distance < cValue):\n",
    "                                depth += 1\n",
    "                            else:\n",
    "                                break\n",
    "                        \n",
    "                        \"\"\"Append the contact pair to the last undercut cutoff value array.\"\"\"\n",
    "                        contactPairs[depth].append(sorted([atomIdxChainA, atomIdxChainB]))\n",
    "\n",
    "                \"\"\"Store the intermolecular contact pairs array in the hdf5 file.\"\"\"\n",
    "                subGroup = group.require_group(name=frameIdx)\n",
    "                for depth, data in enumerate(contactPairs):\n",
    "                    subGroup.create_dataset(name=str(self.cutoffs[depth]), data=data)\n",
    "\n",
    "                    \n",
    "    def _oligomericSize(self):\n",
    "        \"\"\"Get the cutoff value for the descriptor function oligomeric size.\"\"\"\n",
    "        cutoff = self.descriptors['oligomericSize']\n",
    "        \n",
    "        \"\"\"Open the hdf5 file and create the group 'oligomericSize' to store all information\n",
    "        for this descriptor function. The structure of this group is (nFrames, nChains, any)\"\"\"\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.require_group(name='oligomericSize'+str(cutoff))\n",
    "            group2 = f.require_group(name='oligomersInFrame'+str(cutoff))\n",
    "            \n",
    "            \"\"\"Extract the contact pairs for every frame for the descriptor oligomeric size.\"\"\"\n",
    "            for frameIdx in f['contactPairs']:\n",
    "                frameIdx = str(frameIdx)\n",
    "                contactPairs = list(f['contactPairs'][frameIdx][str(cutoff)])\n",
    "                \n",
    "                \"\"\"Array to be filled with information to identify which chains are in contact \n",
    "                within the cutoff value distance. Set is chosen because it has the helpful add\n",
    "                feature, means that if the chain index is already included it is not appended\n",
    "                multiple times, which would be the case when appending to a list.\"\"\"\n",
    "                oligomersInFrame = [set([chain]) for chain in range(self.nChains)]\n",
    "\n",
    "                \n",
    "                \"\"\"Get the chain indices from the atoms in contact and add them to the associated\n",
    "                chain sets.\"\"\"\n",
    "                for atomIdxChainA, atomIdxChainB in contactPairs:\n",
    "                    chainIdxA = int(atomIdxChainA/self.nAtomsPerChain)\n",
    "                    chainIdxB = int(atomIdxChainB/self.nAtomsPerChain)\n",
    "                    oligomersInFrame[chainIdxA].add(chainIdxB)\n",
    "                    oligomersInFrame[chainIdxB].add(chainIdxA)\n",
    "\n",
    "                \"\"\"This routine is necessary to identify larger oligomers, e.g. if chain 0 is in\n",
    "                contact with chain 1, and chain 1 is in contact with chain 2 the adopted structure\n",
    "                is a trimer (0-1-2). So, it units several separated sets.\"\"\"\n",
    "                for i in range(self.nChains):\n",
    "                    for j in range(self.nChains):\n",
    "                        if (i < j):\n",
    "                            if (len(list(oligomersInFrame[i] & oligomersInFrame[j])) != 0):\n",
    "                                united = oligomersInFrame[i].union(oligomersInFrame[j])\n",
    "                                oligomersInFrame[i] = united\n",
    "                                oligomersInFrame[j] = united\n",
    "\n",
    "                \"\"\"Export the data in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=frameIdx, data=[len(chains) for chains in oligomersInFrame])\n",
    "                \n",
    "                subGroup = group2.require_group(name=frameIdx)\n",
    "                for chainIdx, chainIndicesInStructure in enumerate(oligomersInFrame):\n",
    "                    subGroup.create_dataset(name=str(chainIdx), data=list(chainIndicesInStructure))\n",
    "\n",
    "    \n",
    "    def _residuesWithAttribute(self, descriptorName=None, attribute=None):\n",
    "        \"\"\"The user can define an attribute group by augmentation or modification of\n",
    "        the 'attributes' dictionary.\"\"\"\n",
    "        attributes = {'hydrophobic': ['GLY', 'ALA', 'VAL', 'LEU', 'ILE', 'PRO', 'PHE', 'MET', 'TRP'],\n",
    "                      'polar': ['SER', 'THR', 'CYS', 'ASN', 'GLN', 'TYR']}\n",
    "        residuesWithAttribute = attributes[attribute]\n",
    "    \n",
    "    \n",
    "        \"\"\"Get the cutoff value for the descriptor function.\"\"\"\n",
    "        cutoff = self.descriptors[descriptorName]\n",
    "        \n",
    "        \"\"\"Open the hdf5 file and create the group 'descriptorName' to store all information\n",
    "        for this descriptor function. The structure of this group is (nFrames, nChains, any).\"\"\"\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.require_group(name=descriptorName+str(cutoff))\n",
    "\n",
    "            \"\"\"Extract the contact pairs for every frame for the descriptor.\"\"\"\n",
    "            for frameIdx in f['contactPairs']:\n",
    "                frameIdx = str(frameIdx)\n",
    "                contactPairs = list(f['contactPairs'][frameIdx][str(cutoff)])\n",
    "\n",
    "                \"\"\"Array to be filled with information to identify which residues are in contact \n",
    "                within the cutoff value distance. Set is chosen because it has the helpful add\n",
    "                feature, means that if the chain index is already included it is not appended\n",
    "                multiple times, which would be the case when appending to a list.\"\"\"\n",
    "                residuesInContactCounter = np.zeros(nChains, dtype=int)\n",
    "                residuesInContact = []\n",
    "\n",
    "                \"\"\"Get the residue names of the atom indices and see if they belong to the\n",
    "                chosen attribute.\"\"\"\n",
    "                for atomIdxChainA, atomIdxChainB in contactPairs:\n",
    "                    residueNameA = self.resnames[atomIdxChainA]\n",
    "                    residueNameB = self.resnames[atomIdxChainB]\n",
    "\n",
    "                    if (residueNameA in residuesWithAttribute):\n",
    "                        if (residueNameB in residuesWithAttribute):\n",
    "                            \"\"\"Get the chain index and the residue index of the atoms in contact.\"\"\"\n",
    "                            chainIdxA = int(atomIdxChainA/self.nAtomsPerChain)\n",
    "                            chainIdxB = int(atomIdxChainB/self.nAtomsPerChain)\n",
    "                            residueIdxA = int(self.resindices[atomIdxChainA] + chainIdxA*self.nResiduesPerChain)\n",
    "                            residueIdxB = int(self.resindices[atomIdxChainB] + chainIdxB*self.nResiduesPerChain)\n",
    "                            \n",
    "                            \"\"\"Build the 'residuePair' and check if contact between both residues\n",
    "                            has already been recognized. If not, add it to the array 'residuesInContact'\n",
    "                            and increase the counter 'resiudesInContactCounter'.\"\"\"\n",
    "                            residuePair = [residueIdxA, residueIdxB]\n",
    "                            if residuePair not in residuesInContact:\n",
    "                                residuesInContact.append(residuePair)\n",
    "                                residuesInContactCounter[chainIdxA] += 1\n",
    "                                residuesInContactCounter[chainIdxB] += 1\n",
    "                            \n",
    "                \"\"\"Export the data in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=frameIdx, data=residuesInContactCounter)\n",
    "                \n",
    "    \n",
    "    def _hydrophobicContacts(self):\n",
    "        self._residuesWithAttribute(descriptorName='hydrophobicContacts', attribute='hydrophobic')\n",
    "    \n",
    "    \n",
    "    def _polarContacts(self):\n",
    "        self._residuesWithAttribute(descriptorName='polarContacts', attribute='polar')\n",
    "        \n",
    "    \n",
    "    def _compactness(self):\n",
    "        if (self.nChains > 1):\n",
    "            \"\"\"These dictionaries are used later for the selection of atoms.\"\"\"\n",
    "            startIndicesDictionary = {}\n",
    "            endIndicesDictionary = {}\n",
    "            for chainIdx in range(self.nChains):\n",
    "                startIndicesDictionary.update({chainIdx: chainIdx*self.nAtomsPerChain})\n",
    "                endIndicesDictionary.update({chainIdx: chainIdx*self.nAtomsPerChain + self.nAtomsPerChain})\n",
    "    \n",
    "            \"\"\"In order to use this descriptor function, the descriptor function '_oligomersize'\n",
    "            has to be executed previously. If an oligomer is given, its overall compactness is\n",
    "            determined, if not, the compactness of one chain is returned.\"\"\"\n",
    "            with h5.File(self.h5File, 'a') as f:\n",
    "                \n",
    "                \"\"\"Get the cutoff value for the descriptor function oligomeric size.\"\"\"\n",
    "                cutoff = self.descriptors['oligomericSize']\n",
    "                oligomersInFrame='oligomersInFrame'+str(cutoff)\n",
    "                \n",
    "                \"\"\"Create the group 'compactness' if not present yet.\"\"\"\n",
    "                group = f.require_group(name='compactness')\n",
    "\n",
    "                for frameIdx, _ in enumerate(self.universe.trajectory):\n",
    "                    frameIdx = str(frameIdx)\n",
    "                    \n",
    "                    \"\"\"Initialize array which is fed with compactness values later.\"\"\"\n",
    "                    compactnessValues = np.zeros(self.nChains)\n",
    "\n",
    "                    \"\"\"Get unique structures in frame.\"\"\"\n",
    "                    uniqueStructures = []\n",
    "                    for structure in [list(f[oligomersInFrame][frameIdx][key])\\\n",
    "                                      for key in list(f[oligomersInFrame][frameIdx])]:\n",
    "                        if (structure not in uniqueStructures):\n",
    "                            uniqueStructures.append(structure)\n",
    "\n",
    "                    for structure in uniqueStructures:\n",
    "                \n",
    "                        \"\"\"Generate atom group with atoms, which are present in 'structure'.\"\"\"\n",
    "                        for idx, chainIdx in enumerate(structure):\n",
    "                            if (idx == 0):\n",
    "                                atomGroup = self.universe.atoms[startIndicesDictionary[chainIdx]:\\\n",
    "                                                                endIndicesDictionary[chainIdx]]\n",
    "                            else:\n",
    "                                atomGroup += self.universe.atoms[startIndicesDictionary[chainIdx]:\\\n",
    "                                                                endIndicesDictionary[chainIdx]]\n",
    "                                \n",
    "                        \"\"\"Calculate the moment of inertia tensor for the structure and its\n",
    "                        eigenvalues using periodic boundary conditions.\"\"\"\n",
    "                        momentOfInertiaTensor = atomGroup.moment_of_inertia(pbc=True)\n",
    "                        eigenvalues = np.linalg.eigvals(momentOfInertiaTensor)\n",
    "\n",
    "                        \"\"\"Calculate the 'compactness' based on the lowest and highest eigenvalue.\"\"\"\n",
    "                        compactness = abs(round(10*min(eigenvalues)/max(eigenvalues)))\n",
    "\n",
    "                        \"\"\"Fill the previously initialized 'compactnessValues' array with the\n",
    "                        compactness values.\"\"\"\n",
    "                        for chainIdx in structure:\n",
    "                            compactnessValues[chainIdx] = compactness\n",
    "\n",
    "                    \"\"\"Save the data in the hdf5 file.\"\"\"\n",
    "                    group.create_dataset(name=frameIdx, data=compactnessValues)\n",
    "                    \n",
    "        else:\n",
    "            with h5.File(self.h5File, 'a') as f:\n",
    "                group = f.require_group(name='compactness')\n",
    "                allAtoms = self.universe.select_atoms(\"all\")\n",
    "                \n",
    "                for frameIdx, frame in enumerate(self.universe.trajectory):\n",
    "                    compactness = np.zeros(1)\n",
    "                    \"\"\"Calculate the moment of inertia tensor for the structure and its\n",
    "                    eigenvalues using periodic boundary conditions.\"\"\"\n",
    "                    momentOfInertiaTensor = allAtoms.moment_of_inertia(pbc=True)\n",
    "                    eigenvalues = np.linalg.eigvals(momentOfInertiaTensor)\n",
    "                    \n",
    "                    \"\"\"Calculate the 'compactness' based on the lowest and highest eigenvalue.\"\"\"\n",
    "                    compactness[0] = abs(round(10*min(eigenvalues)/max(eigenvalues)))\n",
    "                \n",
    "                    \"\"\"Save the data in the hdf5 file.\"\"\"\n",
    "                    group.create_dataset(name=str(frameIdx), data=compactness)\n",
    "                      \n",
    "                \n",
    "    def _intermolecularSaltBridgeContacts(self):        \n",
    "        \"\"\"At first an atom group containing all atoms of chain A is generated. It is important to\n",
    "        mention that all chains have to be identical!\"\"\"\n",
    "        atomsChainA = self.universe.atoms[:self.nAtomsPerChain]\n",
    "\n",
    "        \"\"\"Now the bonds between the selected atoms are guessed and the elements of these atoms are\n",
    "        identified.\"\"\"\n",
    "        \n",
    "        \"***!!Could be optimized using mdtraj bonds!!***'\"\n",
    "        atomsChainA.guess_bonds()\n",
    "        elements = [atom.type for atom in atomsChainA]\n",
    "        \n",
    "        \"\"\"Initialize positive 'pos' and negative 'neg' charge of that chain and the lists where\n",
    "        the charged atoms are stored, positively charged atom indices are stored in \n",
    "        'saltBridgeAcceptorsChainA', negatively charged atom indices are stored in\n",
    "        saltBridgeDonorsChainA, respectively.\"\"\"\n",
    "        pos = 0\n",
    "        saltBridgeAcceptorsChainA = list()\n",
    "        neg = 0\n",
    "        saltBridgeDonorsChainA = list()\n",
    "        \n",
    "        for atomIdx, element in enumerate(elements):\n",
    "            \n",
    "            \"\"\"If atom with index 'atomIdx' is a nitrogen atom and has four binding partners \n",
    "            (corresponding to a charge of +1) raise the counter of positively charged atoms \n",
    "            'pos' by one and add 'atomIdx' to the list of positively charged atoms \n",
    "            'saltBridgeAcceptorsChainA'.\"\"\" \n",
    "            if (element == 'N'):\n",
    "                bondingDegree = 0\n",
    "                for bond in atomsChainA.bonds:\n",
    "                    if (atomIdx in bond.indices):\n",
    "                        bondingDegree += 1\n",
    "                \n",
    "                if (bondingDegree == 4):\n",
    "                    saltBridgeAcceptorsChainA.append(atomIdx)\n",
    "                    pos += 1\n",
    "\n",
    "            elif (element == 'O'):\n",
    "                \"\"\"If atom with index 'atomIdx' is an oxygen atom and has only one binding partners\n",
    "                with a single bond (corresponding to a charge of -1) and the next atom is also an\n",
    "                oxygen atom (allows identification of carboxylic groups COO-) lower the counter of \n",
    "                negatively charged atoms 'neg' by one and add  'atomIdx' to the list of negatively\n",
    "                charged atoms 'saltBridgeDonorsChainA'.\"\"\"   \n",
    "                bondingDegree = 0\n",
    "                for bond in atomsChainA.bonds:\n",
    "                    if (atomIdx in bond.indices):\n",
    "                        try:\n",
    "                            if (elements[atomIdx + 1] == 'O'):\n",
    "                                bondingDegree += 1\n",
    "                                \n",
    "                        except IndexError:\n",
    "                            pass\n",
    "                        \n",
    "                \"\"\"Also append the index of the next atom, because the charge can be distributed among\n",
    "                both oxygen atoms.\"\"\"\n",
    "                if (bondingDegree == 1):\n",
    "                    saltBridgeDonorsChainA.append(atomIdx)\n",
    "                    neg -= 1\n",
    "        \n",
    "        \"\"\"Total charge of chain A is simply the sum of positively and negatively counted atoms.\"\"\"\n",
    "        chargeChainA = pos + neg\n",
    "        \n",
    "        saltBridgeAcceptorsChainA = np.array(saltBridgeAcceptorsChainA)\n",
    "        saltBridgeDonorsChainA = np.array(saltBridgeDonorsChainA)\n",
    "        \n",
    "        \"\"\"Initialize and fill lists in order to generalize the atom indices for all chains.\"\"\"\n",
    "        saltBridgeAcceptors = list()\n",
    "        saltBridgeDonors = list()\n",
    "        \n",
    "        if (len(saltBridgeAcceptorsChainA) != 0):\n",
    "            for chainIdx in range(self.nChains):\n",
    "                saltBridgeAcceptors.append(saltBridgeAcceptorsChainA + chainIdx*self.nAtomsPerChain)            \n",
    "\n",
    "        else:\n",
    "            for chainIdx in range(self.nChains):\n",
    "                saltBridgeAcceptors.append([])  \n",
    "                \n",
    "                \n",
    "        if (len(saltBridgeDonorsChainA) != 0):\n",
    "            for chainIdx in range(self.nChains):\n",
    "                saltBridgeDonors.append(saltBridgeDonorsChainA + chainIdx*self.nAtomsPerChain)\n",
    "        \n",
    "        else:\n",
    "            for chainIdx in range(self.nChains):\n",
    "                saltBridgeDonors.append([])  \n",
    "                \n",
    "        \n",
    "        \"\"\"Generate a list with atom indices of possible salt bridge contact pairs.\"\"\"\n",
    "        descriptorName = 'intermolecularSaltBridgeContacts'\n",
    "        possibleIntermolecularSaltBridgePairs = list()\n",
    "        findPairs = list()\n",
    "        for chainIdxA, acceptors in enumerate(saltBridgeAcceptors):\n",
    "            for chainIdxB, donors in enumerate(saltBridgeDonors):\n",
    "\n",
    "                \"\"\"Exclude intramolecular salt bridge pairs.\"\"\"\n",
    "                if (chainIdxA != chainIdxB):\n",
    "                    for acceptor in acceptors:\n",
    "                        for donor in donors:\n",
    "                            if ([acceptor, donor] not in findPairs):\n",
    "                                possibleIntermolecularSaltBridgePairs.append([np.sort([acceptor, donor+idx])\\\n",
    "                                                                              for idx in range(2)])\n",
    "                                for idx in range(2):\n",
    "                                    findPairs.append([acceptor, donor+idx])\n",
    "        del findPairs\n",
    "        \n",
    "        saltBridgeDict = {}\n",
    "        for idx, pairs in enumerate(possibleIntermolecularSaltBridgePairs):\n",
    "            for pair in pairs:\n",
    "                saltBridgeDict.update({str(pair): idx})\n",
    "        \n",
    "        nDifferntSaltBridgePairs = len(possibleIntermolecularSaltBridgePairs)\n",
    "        \n",
    "        \"\"\"Get the cutoff value for the descriptor function intermolecularSaltBridgeContacts.\"\"\"\n",
    "        cutoff = self.descriptors[descriptorName]\n",
    "    \n",
    "        \"\"\"Open the hdf5 file and create the group 'desc' to store all information\n",
    "        for this descriptor function. The structure of this group is (nFrames, nChains).\"\"\"\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.require_group(name=descriptorName+str(cutoff))\n",
    "\n",
    "            \"\"\"Extract the contact pairs for every frame for the descriptor.\"\"\"\n",
    "            for frameIdx in range(self.nFrames):\n",
    "                frameIdx = str(frameIdx)\n",
    "                saltBridgeContacts = np.zeros(self.nChains)\n",
    "                noContactInFrame = [True for pairIdx in range(nDifferntSaltBridgePairs)]\n",
    "                \n",
    "                contactPairs = list(f['contactPairs'][frameIdx][str(cutoff)])\n",
    "                for contactPair in contactPairs:\n",
    "                    for possibleSaltBridgePairs in possibleIntermolecularSaltBridgePairs:\n",
    "                        for pair in possibleSaltBridgePairs:\n",
    "                            if np.allclose(pair, np.sort(list(contactPair))):\n",
    "                                \n",
    "                                if noContactInFrame[saltBridgeDict[str(pair)]]:\n",
    "                                    chainIdxA = int(contactPair[0]/self.nAtomsPerChain)\n",
    "                                    saltBridgeContacts[chainIdxA] += 1\n",
    "                                    chainIdxB = int(contactPair[1]/self.nAtomsPerChain)\n",
    "                                    saltBridgeContacts[chainIdxB] += 1\n",
    "                                    \n",
    "                                    noContactInFrame[saltBridgeDict[str(pair)]] = False\n",
    "                                    break\n",
    "\n",
    "                \"\"\"Export the data in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=frameIdx, data=saltBridgeContacts)\n",
    "        \n",
    "        \n",
    "    def _residuesInBeta(self, simplified=False):\n",
    "        \"\"\"For this function, the package mdtraj is used as it enables to compute the secondary\n",
    "        structure using dssp. Please note that the simplified dssp codes ('simplified=True') \n",
    "        are ‘E’== Strand (either of the ‘E’, or ‘B’ non-simplified codes, which are ‘B’ : Residue\n",
    "        in isolated beta-bridge ‘E’ : Extended strand, participates in beta ladder.\"\"\"\n",
    "        \n",
    "        \"\"\"Load the trajectory using mdtraj as 'trajec'.\"\"\"\n",
    "        trajec = mdtraj.load(self.traj, top=self.top)\n",
    "\n",
    "        \"\"\"Open the hdf5 file and create the group 'residuesInBeta' to store all information\n",
    "        for this descriptor function. The structure of this group is (nFrames, nChains).\"\"\"\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.require_group(name='residuesInBeta')\n",
    "\n",
    "            \"\"\"Compute the secondary structures in each frame and count the 'E's (strands, when using\n",
    "            simplified code assignments).\"\"\"\n",
    "            for frameIdx, secondaryStructure in enumerate(mdtraj.compute_dssp(trajec, simplified=simplified)):\n",
    "                residuesInBeta = list()\n",
    "                for residuesInBetaChain in np.split(secondaryStructure, self.nChains):\n",
    "                    residuesInBeta.append(np.count_nonzero(residuesInBetaChain == 'E'))\n",
    "                \n",
    "                \"\"\"Store the number of residues in beta for each frame in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=str(frameIdx), data=residuesInBeta)\n",
    "                \n",
    "    \n",
    "    \"\"\"From here on, a few functions follow which are necessary to compute the nematic and polar\n",
    "    order parameters.\"\"\"\n",
    "    def _tensorOrderParameterQ(self, vector):\n",
    "        \"\"\"Computation of the ordering matrix Q as defined in:\n",
    "        'Thermodynamic analysis of structural transitions during GNNQQNY aggregation'\n",
    "        from Kenneth L. Osborne,  Michael Bachmann, and Birgit Strodel published in\n",
    "        Proteins 2013; 81:1141–1155.\"\"\"\n",
    "        Q = np.zeros((3, 3))\n",
    "        for a, valueA in enumerate(vector):\n",
    "          \n",
    "            \"\"\"Since Q is a symmetric matrix, Qab=Qba applies, such that the loop\n",
    "            can be shortened.\"\"\"\n",
    "            for b, valueB in enumerate(vector[a::]):\n",
    "                if (a == b):\n",
    "                    Qab = 3*valueA*valueB - 1\n",
    "                    Q[a][b] = Qab\n",
    "                    Q[b][a] = Qab\n",
    "                else:\n",
    "                    Qab = 3*valueA*valueB\n",
    "                    Q[a][b] = Qab\n",
    "                    Q[b][a] = Qab\n",
    "            return (Q)\n",
    "        \n",
    "    def _director(self, vectors):\n",
    "        \"\"\"Computation of the direction 'director' most molecules are aligned to. The director\n",
    "        is equal to the eigenvector corresponding to the largest eigenvalue of the ordering\n",
    "        matrix Q.\"\"\"\n",
    "        Q = np.zeros((3, 3))\n",
    "        \n",
    "        \"\"\"Compute Q for every vector.\"\"\"\n",
    "        for vector in vectors:\n",
    "            Q += self._tensorOrderParameterQ(vector)        \n",
    "        \n",
    "        \"\"\"Compute the averaged ordering matrix Q.\"\"\"\n",
    "        Q /= (2*len(vectors))\n",
    "\n",
    "        \"\"\"Determine the eigenvalues and associated eigenvectors of Q.\"\"\"\n",
    "        eigenValues, eigenVectors = np.linalg.eigh(Q)\n",
    "        \n",
    "        \"\"\"Sort the eigenvalues and associated eigenvectors in decreasing order.\"\"\"\n",
    "        idx = eigenValues.argsort()[::-1]   \n",
    "        eigenValues = eigenValues[idx]\n",
    "        eigenVectors = eigenVectors[:,idx]\n",
    "\n",
    "        \"\"\"Return the director by extracting the eigenvector correspoding to the largest\n",
    "        eigenvalue.\"\"\"\n",
    "        director = eigenVectors[:,0]   \n",
    "        return (director)\n",
    "\n",
    "    \n",
    "    def _orderParametersComputation(self, vectors):\n",
    "        \"\"\"Normalize the vectors.\"\"\"\n",
    "        vectorsNotNormalized = vectors.copy()\n",
    "        vectors = list()\n",
    "        for vector in vectorsNotNormalized:\n",
    "            vectors.append(vector/np.linalg.norm(vector))\n",
    "            \n",
    "        \"\"\"Compute the director using the normalized vectors.\"\"\"\n",
    "        director = self._director(vectors)\n",
    "        \n",
    "        \"\"\"Compute the polar and nematic order parameters.\"\"\"\n",
    "        polarOrderParameter = 0\n",
    "        nematicOrderParameter = 0\n",
    "        for vector in vectors:\n",
    "            polarOrderParameter += np.matmul(vector, director)\n",
    "            nematicOrderParameter += 3*np.matmul(vector, director)**2 - 1\n",
    "            \n",
    "        \"\"\"Use the absolut value, because negative only occur as result of the algorithm's\n",
    "        used for computing the eigenvectors.\"\"\"\n",
    "        polarOrderParameter = abs(polarOrderParameter/len(vectors))\n",
    "        nematicOrderParameter = abs(nematicOrderParameter/(2*len(vectors)))\n",
    "        return (polarOrderParameter, nematicOrderParameter)\n",
    "    \n",
    "    \n",
    "    def _orderParameters(self, simplified=False):\n",
    "        \"\"\"Load the trajectory using mdtraj as 'trajec'.\"\"\"\n",
    "        trajec = mdtraj.load(self.traj, top=self.top)\n",
    "        \n",
    "        \"\"\"Compute the secondary structure patterns for each frame.\"\"\"\n",
    "        dssp = mdtraj.compute_dssp(trajec, simplified=simplified)\n",
    "    \n",
    "        \"\"\"In order to use this descriptor function, the descriptor function '_oligomersize'\n",
    "        has to be executed previously. If an oligomer is given, the vectors belonging to both\n",
    "        chain are used for the computation of the order paramters, if not, the order parameters\n",
    "        of one chain with at least to segments are returned.\"\"\"\n",
    "        \n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            \"\"\"Get the cutoff value for the descriptor function oligomeric size.\"\"\"\n",
    "            cutoff = self.descriptors['oligomericSize']\n",
    "            oligomersInFrame='oligomersInFrame'+str(cutoff)\n",
    "\n",
    "            group = f.require_group(name='orderParameter')\n",
    "\n",
    "            for frameIdx, (secondaryStructure, positions) in enumerate(zip(dssp, self.universe.trajectory)):\n",
    "                \"\"\"Check if beta pattern is recognized in frame.\"\"\"\n",
    "                \n",
    "                frameIdx = str(frameIdx)\n",
    "                descriptorValues = np.zeros(self.nChains)\n",
    "                if ('E' in secondaryStructure):\n",
    "                    \"\"\"Get the residue indices belonging to dssp attribute 'E'.\"\"\"\n",
    "                    residueIndices = np.where(secondaryStructure == 'E')[0]+1\n",
    "\n",
    "                    \"\"\"Extract the beta segments.\"\"\"\n",
    "                    diff = residueIndices[1:] - residueIndices[:-1]\n",
    "                    residueIndices = np.array_split(residueIndices, np.where(diff != 1)[0]+1)\n",
    "\n",
    "                    \"\"\"Check if these segments are composed of at least two residues\n",
    "                    and then append the residues to the array 'segments2'.\"\"\"\n",
    "                    segments2 = list()\n",
    "                    for segment in residueIndices:\n",
    "                        if (len(segment) > 1):\n",
    "                            segments2.append(segment)\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                    \"\"\"Check if there are at least two segments composed of at least two residues.\"\"\"\n",
    "                    if (len(segments2) > 1):\n",
    "                        uniqueStructures = []\n",
    "                        for structure in [list(f[oligomersInFrame][frameIdx][key])\\\n",
    "                                          for key in list(f[oligomersInFrame][frameIdx])]:\n",
    "                            if (structure not in uniqueStructures):\n",
    "                                uniqueStructures.append(structure)\n",
    "                                \n",
    "                        Segments = list([] for unique in uniqueStructures)\n",
    "                        breakStatement = False\n",
    "                        for segment in segments2:\n",
    "                            for idx, uniqueStructure in enumerate(uniqueStructures):\n",
    "                                for chain in uniqueStructure:\n",
    "                                    if (int(segment[0]/self.nResiduesPerChain) == chain):\n",
    "                                        Segments[idx].append(segment)\n",
    "                        \n",
    "                        for idx, segments in enumerate(Segments):\n",
    "                            if (len(segments) > 1):\n",
    "                                \"\"\"Compute the NC vector of these segments and append them to 'vectors'.\"\"\"\n",
    "                                vectors = []\n",
    "                                for segment in segments:\n",
    "                                    nAtomPosition = positions.positions[self.nAtomsDict[segment[0]]]\n",
    "                                    cAAtomPosition = positions.positions[self.cAAtomsDict[segment[-1]]]\n",
    "                                    vectors.append(nAtomPosition - cAAtomPosition)\n",
    "        \n",
    "                                \"\"\"Compute the polar and nematic order parameter using the set of vectors\n",
    "                                'vectors'.\"\"\"\n",
    "                                polarOrderParameter, nematicOrderParameter = self._orderParametersComputation(vectors)\n",
    "                                \n",
    "                                if (nematicOrderParameter >= 0.7):\n",
    "                                    if (polarOrderParameter >= 0.7):\n",
    "                                        \"parallel\"\n",
    "                                        for idx in uniqueStructures[idx]:\n",
    "                                            descriptorValues[idx] = 1\n",
    "\n",
    "                                    elif (polarOrderParameter <= 0.4):\n",
    "                                        \"antiparallel\"\n",
    "                                        for idx in uniqueStructures[idx]:\n",
    "                                            descriptorValues[idx] = -1\n",
    "                \n",
    "                \"\"\"Store the order parameter descriptor value for each frame and oligomer\n",
    "                in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=str(frameIdx), data=descriptorValues)\n",
    "\n",
    "    \n",
    "    def _distanceBetweenTwoAtoms(self, frame=0, indices=list()):\n",
    "        \"\"\"Get the box dimensions if the frame.\"\"\"\n",
    "        box = frame.dimensions\n",
    "        \n",
    "        \"\"\"Get the positions of the atoms given.\"\"\"\n",
    "        posConcatenated = frame.positions[indices]\n",
    "        \n",
    "        \"\"\"Compute and return the distance using pbc. The unit of the distance\n",
    "        is angstrom.\"\"\"\n",
    "        return (distance_array(posConcatenated[0], posConcatenated[1], box=box)[0][0])\n",
    "    \n",
    "    \n",
    "    def _nCDistances(self):\n",
    "        \"\"\"'binEdges' is an array, which is used as follows:\n",
    "            example: binEdges = [5.0, 14.5, 20]\n",
    "                     bin1 = [0.0, 5.0]\n",
    "                     bin2 = (5.0, 14.5]\n",
    "                     bin3 = (14.5, 20.0]\n",
    "                     bin4 = (20.0, infinity).\n",
    "            So len(binEdges)+1 bins are generated.\"\"\"\n",
    "        \n",
    "        \"\"\"Get the N and C terminus atom indices. Consider cappings, which are the input\n",
    "        in boolian format.\"\"\"\n",
    "        if self.nCapping:\n",
    "            nTerminusIndices = self.universe.select_atoms(\"resnum 2 and name N\").indices\n",
    "        else:\n",
    "            nTerminusIndices = self.universe.select_atoms(\"resnum 1 and name N\").indices\n",
    "            \n",
    "        if self.cCapping:\n",
    "            selectionString = \"resnum \" + str(self.nResiduesPerChain -1) + \" and name CA\"\n",
    "            cTerminusIndices = self.universe.select_atoms(selectionString).indices\n",
    "        else:\n",
    "            selectionString = \"resnum \" + str(self.nResiduesPerChain) + \" and name CA\"\n",
    "            cTerminusIndices = self.universe.select_atoms(selectionString).indices        \n",
    "        \n",
    "        highestBinIndex = len(self.binEdges) + 1\n",
    "        \n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            \"\"\"Generate the group 'nCDistances' in the hdf5 file.\"\"\"\n",
    "            group = f.require_group(name='nCDistances')\n",
    "\n",
    "            \"\"\"Compute the distance and assign it to a bin.\"\"\"\n",
    "            for frameIdx, frame in enumerate(self.universe.trajectory):\n",
    "                nCDistances = np.zeros(self.nChains)                \n",
    "                for chainIdx, (nTerminusAtomIdx, cTerminusAtomIdx) \\\n",
    "                in enumerate(zip(nTerminusIndices, cTerminusIndices)):\n",
    "                    indices = [nTerminusAtomIdx, cTerminusAtomIdx]\n",
    "                    distance = self._distanceBetweenTwoAtoms(indices=indices, frame=frame)\n",
    "                    \n",
    "                    binned = False\n",
    "                    for descriptorValue, edge in enumerate(self.binEdges, 1):\n",
    "                        if (distance <= edge):\n",
    "                            nCDistances[chainIdx] = descriptorValue\n",
    "                            binned = True\n",
    "                            break\n",
    "                            \n",
    "                    if not binned:\n",
    "                        nCDistances[chainIdx] = highestBinIndex\n",
    "                \n",
    "                group.create_dataset(name=str(frameIdx), data=nCDistances)\n",
    "    \n",
    "    def _ramachandran(self):\n",
    "        warnings.filterwarnings(\"ignore\", message=\"Cannot determine phi and psi angles for the first or last residues\")\n",
    "        \"\"\"This function is only valid for monomers! Keep in mind that cluster indices\n",
    "        can differ.\"\"\"\n",
    "        allAtoms = self.universe.select_atoms(\"all\")\n",
    "\n",
    "        phis, psis = Ramachandran(allAtoms).run().angles.T \n",
    "        phis = phis.T\n",
    "        psis = psis.T\n",
    "        \n",
    "        X = list()\n",
    "        for xArr, yArr in zip(phis[:, :], psis[:, :]):\n",
    "            for x, y in zip(xArr, yArr):\n",
    "                X.append([x, y])\n",
    "        X = np.array(X)\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "        xCluster, yCluster = kmeans.cluster_centers_.T\n",
    "        \n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.create_group('ramachandran')\n",
    "            for frameIdx, (xArr, yArr) in enumerate(zip(phis[:, :], psis[:, :])):\n",
    "                value = 0\n",
    "                for x, y in zip(xArr, yArr):\n",
    "                    value += kmeans.predict([[x, y]])[0]\n",
    "                group.create_dataset(name=str(frameIdx), data=[value])\n",
    "    \n",
    "    def _generateTransitionMatrix(self):\n",
    "        \"\"\"Generate the key names for the state defining functions, which may either be composed\n",
    "        of the descriptors name or of the descriptors name and the associated cutoff value.\"\"\"\n",
    "        descriptorKeys = []\n",
    "        for descriptorName in self.state:\n",
    "            try:\n",
    "                descriptorKeys.append(descriptorName + str(self.descriptors[descriptorName]))\n",
    "            except KeyError:\n",
    "                descriptorKeys.append(descriptorName)\n",
    "        \n",
    "        differentStatesList = []\n",
    "        populationOfStatesDict = {}\n",
    "        transitionMatrixDict = {}\n",
    "        countIdx = 0\n",
    "        with h5.File(self.h5File, 'r') as f:\n",
    "            states = []\n",
    "            for frame in range(self.nFrames):\n",
    "                \"\"\"Extract the states in every frame.\"\"\"\n",
    "                statesInFrame = list([] for chain in range(self.nChains))\n",
    "                for key in descriptorKeys:\n",
    "                    for chainIdx, value in enumerate(f[key][str(frame)]):\n",
    "                        statesInFrame[chainIdx].append(int(value))\n",
    "                \n",
    "                for state in statesInFrame:\n",
    "                    \"\"\"If a state did not occur yet, append it to the list 'differenStatesList',\n",
    "                    update its population and generate an entry in the dictionary \n",
    "                    'transitionMatrixDict' to later relate the entries in the 'transitionMatrix' with\n",
    "                    transitions between states, in other words to relate indices <-> states.\"\"\"\n",
    "                    if (state not in differentStatesList):\n",
    "                        differentStatesList.append(state)\n",
    "                        populationOfStatesDict.update({tuple(state): 1})\n",
    "                        transitionMatrixDict.update({tuple(state): countIdx})\n",
    "                        countIdx += 1\n",
    "    \n",
    "                    else:\n",
    "                        \"\"\"If a state is already known, increase its population by one\n",
    "                        update its population.\"\"\"\n",
    "                        population = populationOfStatesDict[tuple(state)]\n",
    "                        population += 1\n",
    "                        populationOfStatesDict.update({tuple(state): population})\n",
    "                \n",
    "                \"\"\"Append the states observed in this frame to the overall array 'states'.\"\"\"\n",
    "                states.append(statesInFrame)\n",
    "                                \n",
    "            \"\"\"Get the number of different states which have been observed along the\n",
    "            trajectory.\"\"\"\n",
    "            differentStates = len(differentStatesList)\n",
    "            states = np.array(states)\n",
    "            \n",
    "            \"\"\"Initialize the transition matrix.\"\"\"\n",
    "            transitionMatrix = np.zeros((differentStates, differentStates), dtype=int)\n",
    "            \n",
    "            \"\"\"Fill the transition matrix with transition values by counting all observed\n",
    "            transitions between two states.\"\"\"\n",
    "            for chainIdx in range(self.nChains):\n",
    "                stateHistory = states[:, chainIdx, :]\n",
    "                for state1, state2 in zip(stateHistory[:-1], stateHistory[1:]):\n",
    "                    idx1 = transitionMatrixDict[tuple(state1)]\n",
    "                    idx2 = transitionMatrixDict[tuple(state2)]\n",
    "                    transitionMatrix[idx1][idx2] += 1\n",
    "        return (transitionMatrix, transitionMatrixDict)\n",
    "\n",
    "    \n",
    "    def _generateNetwork(self, minPopulation=0.0, minTransition=0.0, gexfName=\"network.gexf\"):\n",
    "        \"\"\"This function generates a .gexf file which can be visualized using the\n",
    "        program 'Gephi'. This files contains the following information:\n",
    "            - population of a state can be visualized by a node's size\n",
    "            - the name of a node is the state\n",
    "            - the amount of transition between two states is encoded in the\n",
    "              line thickness\n",
    "            - the direction of the transition is read to be clockwise.\n",
    "            \n",
    "        Futhermore the user is asked to give 'minPopulation' as input, which is a threshold\n",
    "        for only considering nodes possesing with at least 'minPopulation'*100 percent population\n",
    "        of the maximum observed population\"\"\"\n",
    "        \n",
    "        \n",
    "        transitionMatrix, transitionMatrixDict = self._generateTransitionMatrix()\n",
    "        transitionMatrixNonDiagonal = transitionMatrix.copy()\n",
    "        for idx,_ in enumerate(transitionMatrixNonDiagonal):\n",
    "            transitionMatrixNonDiagonal[idx][idx] = 0\n",
    "                \n",
    "        \"\"\"Get the maximum values for a node pouplation and a transition.\"\"\"\n",
    "        maxPopulation = max(np.diag(transitionMatrix))\n",
    "        maxTransition = np.max(transitionMatrixNonDiagonal)\n",
    "        \n",
    "        \"\"\"Generate a dictionary with nodes and normalized population, which are at least greater than\n",
    "        'minPopulation'.\"\"\"\n",
    "        nodesDict = {}\n",
    "        for state, size in zip(transitionMatrixDict.keys(), np.diagonal(transitionMatrix)):\n",
    "            fraction = size/maxPopulation\n",
    "            if (fraction >= minPopulation):\n",
    "                nodesDict.update({state: size})\n",
    "\n",
    "        \"\"\"Only consider normalized transitions with a value of at least 'minTransition'.\"\"\"\n",
    "        edgesDict = {}\n",
    "        for state1, (idx1, row) in zip(transitionMatrixDict.keys(), enumerate(transitionMatrix)):\n",
    "            for state2, (idx2, transition) in zip(transitionMatrixDict.keys(), enumerate(row)):\n",
    "                if (idx1 != idx2 and transition != 0):\n",
    "                    if (state1 in nodesDict.keys() and state2 in nodesDict.keys()):\n",
    "                        fraction = transition/maxTransition\n",
    "                        if (fraction >= minTransition):\n",
    "                            edgesDict.update({(state1, state2): transition})\n",
    "\n",
    "        G = nx.DiGraph()\n",
    "        for k, v in nodesDict.items():\n",
    "            G.add_node(k, size=float(v))\n",
    "        for k, v in edgesDict.items():\n",
    "            G.add_edge(k[0], k[1], weight=float(v))\n",
    "        nx.draw(G)\n",
    "        nx.write_gexf(G, gexfName)\n",
    "        \n",
    "    \n",
    "    def _OSError(self, function):\n",
    "        try:\n",
    "            function()\n",
    "        except OSError:\n",
    "            pass\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "    def generateNetwork(self, minPopulation=0.0, minTransition=0.0, gexfName=\"network.gexf\"):\n",
    "        for state in self.state:\n",
    "            if (state == 'oligomericSize'):\n",
    "                self._OSError(self._intermolecularContactPairs)\n",
    "                self._OSError(self._oligomericSize)\n",
    "\n",
    "            elif (state == 'intermolecularSaltBridgeContacts'):\n",
    "                self._OSError(self._intermolecularContactPairs)\n",
    "                self._OSError(self._intermolecularSaltBridgeContacts)\n",
    "                \n",
    "            elif (state == 'compactness'):\n",
    "                if (self.nChains > 1):\n",
    "                    self._OSError(self._intermolecularContactPairs)\n",
    "                    self._OSError(self._oligomericSize)\n",
    "                    self._OSError(self._compactness)\n",
    "                else:\n",
    "                    self._OSError(self._compactness)\n",
    "     \n",
    "            elif (state == 'orderParameter'):\n",
    "                self._OSError(self._intermolecularContactPairs)\n",
    "                self._OSError(self._oligomericSize)                \n",
    "                self._OSError(self._orderParameters)\n",
    "                \n",
    "            elif (state == 'hydrophobicContacts'):\n",
    "                self._OSError(self._intermolecularContactPairs)\n",
    "                self._OSError(self._hydrophobicContacts)\n",
    "                \n",
    "            elif (state == 'polarContacts'):\n",
    "                self._OSError(self._intermolecularContactPairs)\n",
    "                self._OSError(self._polarContacts)\n",
    "                \n",
    "            elif (state == 'residuesInBeta'):\n",
    "                self._OSError(self._residuesInBeta)\n",
    "            \n",
    "            elif (state == 'nCDistances'):\n",
    "                self._OSError(self._nCDistances)\n",
    "                \n",
    "            elif (state == 'ramachandran'):\n",
    "                self._OSError(self._ramachandran)\n",
    "                \n",
    "        self._generateNetwork(minPopulation=minPopulation, minTransition=minTransition, gexfName=gexfName)\n",
    "     \n",
    "    \n",
    "    def correlationCoefficients(self):\n",
    "        descriptorKeys = []\n",
    "        for descriptorName in self.state:\n",
    "            try:\n",
    "                descriptorKeys.append(descriptorName + str(self.descriptors[descriptorName]))\n",
    "            except KeyError:\n",
    "                descriptorKeys.append(descriptorName)\n",
    "        \n",
    "        with h5.File(self.h5File, 'r') as f:\n",
    "            correlations = {}\n",
    "            for idxA, keyA in enumerate(descriptorKeys, 1):\n",
    "                for keyB in descriptorKeys[idxA:]:\n",
    "                    valuesA = np.zeros((self.nFrames, self.nChains))\n",
    "                    valuesB = valuesA.copy()\n",
    "                    \n",
    "                    for frame in range(self.nFrames):\n",
    "                        valA = list(f[keyA][str(frame)])\n",
    "                        valB = list(f[keyB][str(frame)])\n",
    "                        for chainIdx, (a, b) in enumerate(zip(valA, valB)):\n",
    "                            valuesA[frame][chainIdx] = a\n",
    "                            valuesB[frame][chainIdx] = b\n",
    "                    \n",
    "                    correlationCoefficients = np.zeros(self.nChains)\n",
    "                    for chainIdx, (valsA, valsB) in enumerate(zip(valuesA.T, valuesB.T)):\n",
    "                        correlationCoefficients[chainIdx] = np.corrcoef(valsA, valsB)[0][1]\n",
    "                    correlations.update({keyA + '+' + keyB: np.mean(correlationCoefficients)})\n",
    "        return (correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn ein Cutoff mit einer Nachkommastelle gegeben ist, müssen alle anderen auch mit einer Nachkommastelle gegeben werden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top ='0-5_cc.pdb'\n",
    "traj ='0-10_cc_skip10.xtc'\n",
    "desc = {'oligomericSize': 5.0, 'hydrophobicContacts': 4.5}\n",
    "state = ['oligomericSize', 'hydrophobicContacts']\n",
    "nChains = 2\n",
    "tn = TransitionNetworks(top=top, traj=traj, desc=desc, nChains=nChains, state=state, h5File='transitionNetworkWithHydrophobic.hdf5')\n",
    "#tn.generateNetwork(minPopulation=0.01, minTransition=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = tn.correlationCoefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oligomericSize5.0+hydrophobicContacts4.5': 0.71463552401355}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
